<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="MARJu3erA7Z6jybcmR5fgSNRNtCNYMAYkk0jidGGr8A"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Junshen Xu</title> <meta name="author" content="Junshen Xu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon_v2.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://daviddmc.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6A%75%6E%73%68%65%6E@%6D%69%74.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=qNk6tgcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/daviddmc" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/junshen-xu-30444b129" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span style="font-weight: 500">Junshen</span> Xu  <br class="d-md-none">(徐 <span style="font-weight: 500">俊燊</span>) </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address d-none d-md-block"> <p>Room 36-776A</p> <p>50 Vassar St. </p> <p>(MIT building 36) </p> <p>Cambridge, MA 02139</p> </div> </div> <div class="clearfix"> <p>Hi! I am currently a fifth-year Ph.D. student at MIT majoring in Electrical Engineering and Computer Science. My research focuses on machine learning and developing robust and efficient algorithms driven by clinical problems. Applications include motion-robust 3D rendering of the human brain, real-time quality assessment in MR scans as well as pose estimation and motion characterization of fetuses. I am advised by Prof. <a href="https://www.rle.mit.edu/people/directory/elfar-adalsteinsson/" rel="external nofollow noopener" target="_blank">Elfar Adalsteinsson</a> and collaborate closely with Prof. <a href="https://people.csail.mit.edu/polina/" rel="external nofollow noopener" target="_blank">Polina Golland</a> and Prof. <a href="https://scholar.google.com/citations?user=W4dqZ7EAAAAJ" rel="external nofollow noopener" target="_blank">P. Ellen Grant</a>.</p> <p>I also did summer internships at Google and Meta, working on automated Ads bidding and large-scale video recommendation systems respectively.</p> <p>Prior to MIT, I received my Bachelor’s degree from Tsinghua University in 2018. I also spent a summer as a research assistant at Stanford, where I was advised by Prof. <a href="https://web.stanford.edu/~pauly/" rel="external nofollow noopener" target="_blank">John Pauly</a> and Prof. <a href="https://profiles.stanford.edu/greg-zaharchuk" rel="external nofollow noopener" target="_blank">Greg Zaharchuk</a>.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Apr 25, 2023</th> <td> We just released <a href="https://github.com/daviddmc/NeSVoR" rel="external nofollow noopener" target="_blank">NeSVoR</a> v0.2.0. Check it out! </td> </tr> <tr> <th scope="row">Apr 19, 2023</th> <td> I successfully defended my doctoral thesis today! </td> </tr> <tr> <th scope="row">Mar 16, 2023</th> <td> Our paper entitled “Latent Signal Models: Learning Compact Representations of Signal Evolution for Improved Time-Resolved, Multi-contrast MRI” was accepted by MRM! </td> </tr> <tr> <th scope="row">Feb 21, 2023</th> <td> Our paper entitled “Zero-Shot Self-Supervised Joint Temporal Image and Sensitivity Map Reconstruction via Linear Latent Space” was accepted by MIDL 2023! </td> </tr> <tr> <th scope="row">Jan 9, 2023</th> <td> Our paper entitled “NeSVoR: Implicit Neural Representation for Slice-to-Volume Reconstruction in MRI” was accepted by IEEE TMI! </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <img id="recon_60_axgif" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/recon_60_ax.gif"><div id="recon_60_axgif-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('recon_60_axgif-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="recon_60_axgif-modal-img"> </div> <script>var modal=document.getElementById("recon_60_axgif-modal"),img=document.getElementById("recon_60_axgif"),modalImg=document.getElementById("recon_60_axgif-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="10015091" class="col-sm-8 col-md-9"> <div class="title">NeSVoR: Implicit Neural Representation for Slice-to-Volume Reconstruction in MRI</div> <div class="author"> <em>Junshen Xu</em>, <a href="https://dcmoyer.github.io/" rel="external nofollow noopener" target="_blank">Daniel Moyer</a>, <a href="https://scholar.google.com/citations?user=mXUhe04AAAAJ" rel="external nofollow noopener" target="_blank">Borjan Gagoski</a>, <a href="https://scholar.harvard.edu/iglesias" rel="external nofollow noopener" target="_blank">Juan Eugenio Iglesias</a>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'P. Ellen Grant, Polina Golland, Elfar Adalsteinsson' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Medical Imaging</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/10015091" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a href="https://www.techrxiv.org/articles/preprint/NeSVoR_Implicit_Neural_Representation_for_Slice-to-Volume_Reconstruction_in_MRI/21398868" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/daviddmc/NeSVoR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1109/TMI.2023.3236216" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/TMI.2023.3236216" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Reconstructing 3D MR volumes from multiple motion-corrupted stacks of 2D slices has shown promise in imaging of moving subjects, e.g., fetal MRI. However, existing slice-to-volume reconstruction methods are time-consuming, especially when a high-resolution volume is desired. Moreover, they are still vulnerable to severe subject motion and when image artifacts are present in acquired slices. In this work, we present NeSVoR, a resolution-agnostic slice-to-volume reconstruction method, which models the underlying volume as a continuous function of spatial coordinates with implicit neural representation. To improve robustness to subject motion and other image artifacts, we adopt a continuous and comprehensive slice acquisition model that takes into account rigid inter-slice motion, point spread function, and bias fields. NeSVoR also estimates pixel-wise and slice-wise variances of image noise and enables removal of outliers during reconstruction and visualization of uncertainty. Extensive experiments are performed on both simulated and in vivo data to evaluate the proposed method. Results show that NeSVoR achieves state-of-the-art reconstruction quality while providing two to ten-fold acceleration in reconstruction times over the state-of-the-art algorithms.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <img id="svortpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/svort.png"><div id="svortpng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('svortpng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="svortpng-modal-img"> </div> <script>var modal=document.getElementById("svortpng-modal"),img=document.getElementById("svortpng"),modalImg=document.getElementById("svortpng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="10.1007/978-3-031-16446-0_1" class="col-sm-8 col-md-9"> <div class="title">SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI</div> <div class="author"> <em>Junshen Xu</em>, <a href="https://dcmoyer.github.io/" rel="external nofollow noopener" target="_blank">Daniel Moyer</a>, <a href="https://scholar.google.com/citations?user=W4dqZ7EAAAAJ" rel="external nofollow noopener" target="_blank">P. Ellen Grant</a>, <a href="https://people.csail.mit.edu/polina/" rel="external nofollow noopener" target="_blank">Polina Golland</a>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Juan Eugenio Iglesias, Elfar Adalsteinsson' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Medical Image Computing and Computer Assisted Intervention – MICCAI 2022</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-16446-0_1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a href="http://arxiv.org/abs/2206.10802" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/daviddmc/SVoRT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/svort_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Volumetric reconstruction of fetal brains from multiple stacks of MR slices, acquired in the presence of almost unpredictable and often severe subject motion, is a challenging task that is highly sensitive to the initialization of slice-to-volume transformations. We propose a novel slice-to-volume registration method using Transformers trained on synthetically transformed data, which model multiple stacks of MR slices as a sequence. With the attention mechanism, our model automatically detects the relevance between slices and predicts the transformation of one slice using information from other slices. We also estimate the underlying 3D volume to assist slice-to-volume registration and update the volume and transformations alternately to improve accuracy. Results on synthetic data show that our method achieves lower registration error and better reconstruction quality compared with existing state-of-the-art methods. Experiments with real-world MRI data are also performed to demonstrate the ability of the proposed model to improve the quality of 3D reconstruction under severe fetal motion.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <img id="iqa_looppng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/iqa_loop.png"><div id="iqa_looppng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('iqa_looppng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="iqa_looppng-modal-img"> </div> <script>var modal=document.getElementById("iqa_looppng-modal"),img=document.getElementById("iqa_looppng"),modalImg=document.getElementById("iqa_looppng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="https://doi.org/10.1002/mrm.29106" class="col-sm-8 col-md-9"> <div class="title">Automated detection and reacquisition of motion-degraded images in fetal HASTE imaging at 3 T</div> <div class="author"> <a href="https://scholar.google.com/citations?user=mXUhe04AAAAJ" rel="external nofollow noopener" target="_blank">Borjan Gagoski*</a>, <em>Junshen Xu*</em>, Paul Wighton, M. Dylan Tisdall, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Robert Frost, Wei-Ching Lo, Polina Golland, Andre Kouwe, Elfar Adalsteinsson, P. Ellen Grant' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Magnetic Resonance in Medicine</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.29106" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="https://doi.org/10.1002/mrm.29106" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1002/mrm.29106" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Purpose: Fetal brain Magnetic Resonance Imaging suffers from unpredictable and unconstrained fetal motion that causes severe image artifacts even with half-Fourier single-shot fast spin echo (HASTE) readouts. This work presents the implementation of a closed-loop pipeline that automatically detects and reacquires HASTE images that were degraded by fetal motion without any human interaction. Methods: A convolutional neural network that performs automatic image quality assessment (IQA) was run on an external GPU-equipped computer that was connected to the internal network of the MRI scanner. The modified HASTE pulse sequence sent each image to the external computer, where the IQA convolutional neural network evaluated it, and then the IQA score was sent back to the sequence. At the end of the HASTE stack, the IQA scores from all the slices were sorted, and only slices with the lowest scores (corresponding to the slices with worst image quality) were reacquired. Results: The closed-loop HASTE acquisition framework was tested on 10 pregnant mothers, for a total of 73 acquisitions of our modified HASTE sequence. The IQA convolutional neural network, which was successfully employed by our modified sequence in real time, achieved an accuracy of 85.2% and area under the receiver operator characteristic of 0.899. Conclusion: The proposed acquisition/reconstruction pipeline was shown to successfully identify and automatically reacquire only the motion degraded fetal brain HASTE slices in the prescribed stack. This minimizes the overall time spent on HASTE acquisitions by avoiding the need to repeat the entire stack if only few slices in the stack are motion-degraded.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <img id="fetal_posepng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/fetal_pose.png"><div id="fetal_posepng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('fetal_posepng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="fetal_posepng-modal-img"> </div> <script>var modal=document.getElementById("fetal_posepng-modal"),img=document.getElementById("fetal_posepng"),modalImg=document.getElementById("fetal_posepng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="10.1007/978-3-030-32251-9_44" class="col-sm-8 col-md-9"> <div class="title">Fetal Pose Estimation in Volumetric MRI Using a 3D Convolution Neural Network</div> <div class="author"> <em>Junshen Xu*</em>, <a href="https://scholar.google.com/citations?user=M6LlDA4AAAAJ" rel="external nofollow noopener" target="_blank">Molin Zhang*</a>, <a href="https://scholar.google.com/citations?user=HYUyyTsAAAAJ" rel="external nofollow noopener" target="_blank">Esra Abaci Turk</a>, Larry Zhang, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'P. Ellen Grant, Kui Ying, Polina Golland, Elfar Adalsteinsson' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Medical Image Computing and Computer Assisted Intervention – MICCAI 2019</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-32251-9_44" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a href="http://arxiv.org/abs/1907.04500" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/daviddmc/fetal-pose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/fetal_pose_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>The performance and diagnostic utility of magnetic resonance imaging (MRI) in pregnancy is fundamentally constrained by fetal motion. Motion of the fetus, which is unpredictable and rapid on the scale of conventional imaging times, limits the set of viable acquisition techniques to single-shot imaging with severe compromises in signal-to-noise ratio and diagnostic contrast, and frequently results in unacceptable image quality. Surprisingly little is known about the characteristics of fetal motion during MRI and here we propose and demonstrate methods that exploit a growing repository of MRI observations of the gravid abdomen that are acquired at low spatial resolution but relatively high temporal resolution and over long durations (10–30 min). We estimate fetal pose per frame in MRI volumes of the pregnant abdomen via deep learning algorithms that detect key fetal landmarks. Evaluation of the proposed method shows that our framework achieves quantitatively an average error of 4.47 mm and 96.4% accuracy (with error less than 10 mm). Fetal pose estimation in MRI time series yields novel means of quantifying fetal movements in health and disease, and enables the learning of kinematic models that may enhance prospective mitigation of fetal motion artifacts during MRI acquisition.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <img id="odepng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/ode.png"><div id="odepng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('odepng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="odepng-modal-img"> </div> <script>var modal=document.getElementById("odepng-modal"),img=document.getElementById("odepng"),modalImg=document.getElementById("odepng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="10.1007/978-3-030-87202-1_21" class="col-sm-8 col-md-9"> <div class="title">Multi-scale Neural ODEs for 3D Medical Image Registration</div> <div class="author"> <em>Junshen Xu</em>, Eric Z. Chen, Xiao Chen, Terrence Chen, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Shanhui Sun' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Medical Image Computing and Computer Assisted Intervention – MICCAI 2021</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-87202-1_21" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a href="http://arxiv.org/abs/2106.08493" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/pdf/ode_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Image registration plays an important role in medical image analysis. Conventional optimization based methods provide an accurate estimation due to the iterative process at the cost of expensive computation. Deep learning methods such as learn-to-map are much faster but either iterative or coarse-to-fine approach is required to improve accuracy for handling large motions. In this work, we proposed to learn a registration optimizer via a multi-scale neural ODE model. The inference consists of iterative gradient updates similar to a conventional gradient descent optimizer but in a much faster way, because the neural ODE learns from the training data to adapt the gradient efficiently at each iteration. Furthermore, we proposed to learn a modal-independent similarity metric to address image appearance variations across different image contrasts. We performed evaluations through extensive experiments in the context of multi-contrast 3D MR images from both public and private data sources and demonstrate the superior performance of our proposed methods.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6A%75%6E%73%68%65%6E@%6D%69%74.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=qNk6tgcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/daviddmc" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/junshen-xu-30444b129" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Junshen Xu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: May 06, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NYJ88YK0VS"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NYJ88YK0VS");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>